<!DOCTYPE html>
<body style="position: relative;">
  <video id="video" style="position: fixed; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover;"></video>
  <canvas id="canvas" width="300" height="200" style="display:none;"></canvas>
  <div style="position: fixed; left: 20px; bottom: 40px; font-size: 40px; color: white; text-shadow: -1px -1px 0 #000, 1px -1px 0 #000, -1px 1px 0 #000, 1px 1px 0 #000;">
    <div><label for="">QRCode Detected:</label><div id="qrcodeResult"></div></div>
    <div><label for="">Devices:</label><div id="devices"></div></div>
  </div>
  <script src="https://unpkg.com/vconsole@latest/dist/vconsole.min.js"></script>
  <script>
    var vConsole = new window.VConsole();
    function loadScript(url) {
      return new Promise((resolve, reject) => {
        let script = document.createElement("script");
        script.setAttribute("async", "");
        script.setAttribute("type", "text/javascript");
        script.setAttribute("id", "opencvjs");
        script.addEventListener("load", async () => {
          if (cv.getBuildInformation) {
            console.log(cv.getBuildInformation());
            resolve();
          } else {
            // WASM
            if (cv instanceof Promise) {
              cv = await cv;
              console.log(cv.getBuildInformation());
              resolve();
            } else {
              cv["onRuntimeInitialized"] = () => {
                console.log(cv.getBuildInformation());
                resolve();
              };
            }
          }
        });
        script.addEventListener("error", () => {
          reject();
        });
        script.src = url;
        let node = document.getElementsByTagName("script")[0];
        node.parentNode.insertBefore(script, node);
      });
    };

    async function fetchModelsData(name) {
      const response = await fetch(`./models/${name}`, { method: "GET" });
      const data = await response.arrayBuffer();
      return new Uint8Array(data);
    };

    let qrcode_detector = undefined;
    const OPENCV_URL = "./opencv.js";
    
    loadScript(OPENCV_URL)
      .then(() => loadModels())
      .catch(() => alert("Failed to load " + OPENCV_URL));

    async function loadModels() {
      if (qrcode_detector)
        return;
      
      const detect_proto = "detect.prototxt";
      const detect_weight = "detect.caffemodel";
      const sr_proto = "sr.prototxt";
      const sr_weight = "sr.caffemodel";

      const dp = await fetchModelsData(detect_proto);
      const dw = await fetchModelsData(detect_weight);
      const sp = await fetchModelsData(sr_proto);
      const sw = await fetchModelsData(sr_weight);

      cv.FS_createDataFile("/", "detect.prototxt", dp, true, false, false);
      cv.FS_createDataFile("/", "detect.caffemodel", dw, true, false, false);
      cv.FS_createDataFile("/", "sr.prototxt", sp, true, false, false);
      cv.FS_createDataFile("/", "sr.caffemodel", sw, true, false, false);

      qrcode_detector = new cv.wechat_qrcode_WeChatQRCode(
        "detect.prototxt",
        "detect.caffemodel",
        "sr.prototxt",
        "sr.caffemodel"
      );
    }

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    function opencvDetect() {
      if (!qrcode_detector)
        return;
      let inputImage = cv.imread('canvas', cv.IMREAD_GRAYSCALE);
      let points_vec = new cv.MatVector();
      let res = qrcode_detector.detectAndDecode(inputImage, points_vec);
      if (res.size() > 0) {
        let qrcodes = [];
        let divQRCodeResult = document.getElementById('qrcodeResult');  
        let qrcodeResults = [];
        for (let i=0; i<res.size(); i++) {
          qrcodeResults.push(res.get(i));
        }
        divQRCodeResult.innerHTML = qrcodeResults.join("<br>");
      }
      return res.size() > 0;
    }

    let framesWithoutQRCode = 0;
    let zoomLevel = 1;

    async function startCamera() {
      try {
        const devices = await navigator.mediaDevices.enumerateDevices();

        console.log(devices);
        const videoDevices = devices.filter(device => device.kind === 'videoinput');
        let backCameraDevice = null;

        if (videoDevices.length === 0) {
          alert('No camera available.');
          return;
        }

        let deviceLabels = videoDevices.map(device => device.label).join('<br>');
        document.getElementById("devices").innerHTML = deviceLabels;
        
        for (const device of videoDevices) {
          if (device.label.toLowerCase().includes('back')) {
            backCameraDevice = device;
            break;
          }
        }

        const deviceId = backCameraDevice ? backCameraDevice.deviceId : videoDevices[0].deviceId;

        const stream = await navigator.mediaDevices.getUserMedia({
          video: backCameraDevice ? { deviceId: backCameraDevice.deviceId } : { facingMode: 'environment' },
        });

        video.srcObject = stream;
        video.setAttribute('playsinline', 'true');
        video.play();

        video.onloadedmetadata = () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
          requestAnimationFrame(tick);
        };
      } catch (err) {
        console.error('Error accessing the camera:', err);
      }
    }

    function tick() {
      if (video.readyState !== video.HAVE_ENOUGH_DATA) {
        return;
      }
      
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      let detected = opencvDetect();
      if (detected) {
        framesWithoutQRCode = 0;
        if (zoomLevel !== 1) {
          zoomLevel = 1;
          setCameraZoomLevel(video.srcObject, zoomLevel);
        }
      } else {
        framesWithoutQRCode++;
        if (framesWithoutQRCode >= 30 * 1) {
          if (zoomLevel !== 2) {
            zoomLevel = 2;
            setCameraZoomLevel(video.srcObject, zoomLevel);
          }
        }
      }
      requestAnimationFrame(tick);
    }

    function setCameraZoomLevel(mediaStream, zoomLevel) {
      console.log(`setCameraZoomLevel to ${zoomLevel}`);
      const [track] = mediaStream.getVideoTracks();
      const capabilities = track.getCapabilities();
      const settings = track.getSettings();

      // Check whether zoom is supported or not.
      if (!('zoom' in settings)) {
        console.error('Zoom is not supported by ' + track.label);
      }

      if (zoomLevel < capabilities.zoom.min)
        zoomLevel = capabilities.zoom.min;
      if (zoomLevel > capabilities.zoom.max)
        zoomLevel = capabilities.zoom.max;
      
      console.log('Resolve zoomLevel to ' + zoomLevel + ' (min: ' + capabilities.zoom.min + ', max: ' + capabilities.zoom.max + ')');
      
      track.applyConstraints({advanced: [ {zoom: zoomLevel} ]});
    }

    startCamera();
    </script>
</body>